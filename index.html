<html>
<head>
  <style>
    table, th, td {
      border: 1px solid black;
      border-collapse: collapse;
    }
  </style>
</head>
<body>
<h1>Group 6 Final Report</h1>
<h2>1) Introduction</h2>
<p>
  &emsp; a) Literature Review <br>
  &emsp; &emsp;   i)&emsp;Lu was concerned with flight prices as a time-series and <br>
  &emsp;&emsp;&emsp;  &emsp;when to buy/wait. Lu found the AdaBoost-DecisionTree <br>
  &emsp;&emsp;&emsp;  &emsp;algorithm had the best performance (61.35% than random <br>
  &emsp;&emsp;&emsp;  &emsp;purchase strategy) over the eight routes examined; K-means <br>
  &emsp;&emsp;&emsp;  &emsp;and EM to address outliers. <br>
  &emsp; &emsp;ii) &emsp;S. Gupta and N. Gupta used <q>a combination of decision tree <br>
  &emsp;&emsp;&emsp;  &emsp;algorithms, k Nearest Neighbors (KNN), and linear <br>
  &emsp;&emsp;&emsp;  &emsp;regression</q> on historical trends to forecast flight prices. <br>
  &emsp;&emsp;&emsp;  &emsp;Their Random Forest Regressor and Decision Tree Regressor <br>
  &emsp;&emsp;&emsp;  &emsp;had r2 scores of .81 and .67 respectively. <br>
  &emsp;&emsp;iii) &emsp;Tziridis et al. evaluated different regression models <br>
  &emsp;&emsp;&emsp;  &emsp;including random forests and support vector machines on a <br>
  &emsp;&emsp;&emsp;  &emsp;dataset of over 1,000 flights, focusing on how departure time <br>
  &emsp;&emsp;&emsp;  &emsp;and the number of stops a given flight had would impact the <br>
  &emsp;&emsp;&emsp;  &emsp;prediction accuracy. They found that the bagging regression <br>
  &emsp;&emsp;&emsp;  &emsp;tree model had the highest accuracy of 87.42%. <br>
  &emsp; b) Dataset Description <br>
  &emsp; &emsp;   i)&emsp;The data will contain prices of flights over time, consisting <br>
  &emsp;&emsp;&emsp;  &emsp;of fixed destinations and dates. The data contains information <br>
  &emsp;&emsp;&emsp;  &emsp;for United Airfare flight SFO-LAX <br>
  &emsp; c) Dataset Link: <a href="https://www.kaggle.com/code/andrewrliu/airfare-predictor-pt-1/input">Airfare Predictor (pt.1)</a>
</p>
<h2>2) Problem Description and Motivation</h2>
<p>
  The distribution of flight prices is inherently non-linear and does not follow an easily predictable distribution. The goal of this paper is to create a machine learning approach to the problem of the distributions of ticket flight prices when given partial information about the distribution. In other words, by giving an earlier part of the distribution, the latter part of the distribution will be predicted allowing for educated choices on when to purchase a flight ticket at the cheapest time.

</p>
<h2>3) Methods</h2>
<p>
  &emsp; a) Preprocessing methods <br>
  &emsp; &emsp;   i)&emsp; Visualization<br>
  &emsp;&emsp;&emsp;  &emsp; For each flight, a data point was created containing a column of ticket prices<br>
  &emsp;&emsp;&emsp;  &emsp; and a column containing the number of days. This matrix was used to create a<br>
  &emsp;&emsp;&emsp;  &emsp; scatterplot of prices over different number of days befor the plane's departure<br>
  &emsp; &emsp;ii) &emsp; Removing Outliers<br>
  &emsp;&emsp;&emsp;  &emsp; After visualizing the data, some of the scatterplots showed signs of outliers.<br>
  &emsp;&emsp;&emsp;  &emsp; Most of these outliers were located in the couple of days leading up to each <br>
  &emsp;&emsp;&emsp;  &emsp; flight. Consequently, we decided to remove the data one and two days in <br>
   &emsp;&emsp;&emsp;  &emsp; advance for each flight.This left us with 55 data points for each of the 95 flights.<br>
  <!--<h2>Flight Price with Respect to Days Before Departure</h2><br>
  <img src="./docs/assets/css/Screenshot_3-7-2024_8394_colab.research.google.png" title="Data vs. Processed Data" width="75%" height="75%"><br><br>-->
  &emsp; b) Supervised Learning methods <br>
  &emsp;  &emsp;  i) &emsp;Direct Architecture<br>
  &emsp;&emsp;&emsp;  &emsp; This architecture takes the direct approach to the problem, taking each of the days  <br>
  &emsp;&emsp;&emsp;  &emsp; inside of the prior distribution as a feature to predict the remaining days inside of the  <br>
  &emsp;&emsp;&emsp;  &emsp; distribution as an output. Thus if one wished to predict the distribution using the <br>
  &emsp;&emsp;&emsp;  &emsp; information up to 33 days from the flight, then each one of those 22 days will be a  <br>
  &emsp;&emsp;&emsp;  &emsp; feature, with 31 outputs. This approach however suffers from the fact that with only 95  <br>
  &emsp;&emsp;&emsp;  &emsp; data points in total there exists a great deal of features compared to data points. In this   <br>
  &emsp;&emsp;&emsp;  &emsp; implementation various different algorithms were attempted with those being Multi-level    <br>
  &emsp;&emsp;&emsp;  &emsp; perceptron regressor, Random Forest Regressor, and Linear Regression with polynomial    <br>
  &emsp;&emsp;&emsp;  &emsp; features and Lasso regularization.    <br>
  &emsp;  &emsp; ii) &emsp;Iterative Architecture<br>
  &emsp;&emsp;&emsp;  &emsp; This architecture attempts to understand the relationships between the points in an<br>
  &emsp;&emsp;&emsp;  &emsp; iterative manner, by the assumption that if one has the prices from days 33 to 55, then <br>
  &emsp;&emsp;&emsp;  &emsp; predicting the price on day 32 would be ‘easier’ compared to predicting the entire <br>
  &emsp;&emsp;&emsp;  &emsp; distribution at one time. Thus this approach trains multiple models with a step of 1 day <br>
  &emsp;&emsp;&emsp;  &emsp; until reaching the endpoint (day 3), progressively increasing the number of days in the X <br>
  &emsp;&emsp;&emsp;  &emsp; set in the form of adding a new feature. Overall this architecture has the major drawback <br>
  &emsp;&emsp;&emsp;  &emsp; of requiring a different model to understand the relationship between each point and the <br>
  &emsp;&emsp;&emsp;  &emsp; points prior to it, which can make this approach much more expensive compared to the <br>
  &emsp;&emsp;&emsp;  &emsp; direct approach. In the implementation of this architecture Random Forest Regressor<br>
  &emsp;&emsp;&emsp;  &emsp; and Multi-level perceptron versions were used.<br>
   &emsp;  &emsp; iii) &emsp;Iterative Architecture with Soft-Clustering<br>
  &emsp;&emsp;&emsp;  &emsp; This architecture uses the iterative architecture, however in addition to each model there <br>
  &emsp;&emsp;&emsp;  &emsp; is an unsupervised soft-classification scheme (Gaussian Mixture Model in this case) <br>
  &emsp;&emsp;&emsp;  &emsp; which was trained to recognize different types of distributions. For each one of these <br>
  &emsp;&emsp;&emsp;  &emsp; gaussians, a separate random forest regressor model was fitted, resulting in 3 random <br>
  &emsp;&emsp;&emsp;  &emsp; forest models per step. By taking a weighted average for each point using the <br>
  &emsp;&emsp;&emsp;  &emsp; confidence percentages for each gaussian using the current X, this method promises <br>
  &emsp;&emsp;&emsp;  &emsp; greater understanding compared to simply using the iterative approach as it will use the <br>
  &emsp;&emsp;&emsp;  &emsp; soft-clustering understanding of distributions alongside the supervised learning <br>
  &emsp;&emsp;&emsp;  &emsp; predictive elements to create an ideal model at the  cost to performance given the fact <br>
  &emsp;&emsp;&emsp;  &emsp; that for each step a GMM will need to be fitted, alongside 3 Random Forest <br>
  &emsp;&emsp;&emsp;  &emsp; Regressions.<br>

</p>
<h2>4) Results and Discussion</h2>
<p>
  &emsp; a) 44 point split <br>
  &emsp;  &emsp;  i) &emsp;Direct Approach Results<br>
  &emsp;  &emsp; &emsp;  1) &emsp;MLP<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 755.99<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 79.90%<br>
  <img src="./docs/assets/css/44/dmlp81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/44/dmlp87.png" title="MLP4481"><br>
  &emsp;  &emsp; &emsp;  2) &emsp;RFR<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 989.08<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 80.86%<br>
   <img src="./docs/assets/css/44/drf81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/44/drf87.png" title="MLP4481"><br>
  &emsp;  &emsp; &emsp;  3) &emsp;Lasso<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 5795.66<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 60.29%<br>
  <img src="./docs/assets/css/44/dl81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/44/dl87.png" title="MLP4481"><br>
  &emsp;  &emsp; ii) &emsp;Iterative Architecture and Iterative with Soft-clustering Results<br>
  &emsp;  &emsp; &emsp;  1) &emsp;MLP<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 1095.71<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 72.63%<br>
  <img src="./docs/assets/css/44/imlp81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/44/imlp87.png" title="MLP4481"><br>
  &emsp;  &emsp; &emsp;  2) &emsp;RFR<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 1092.52<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 80.53%<br>
  <img src="./docs/assets/css/44/irf81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/44/irf87.png" title="MLP4481"><br>
  &emsp;  &emsp; &emsp;  3) &emsp;GMM<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 1672.85<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 77.37%<br>
  <img src="./docs/assets/css/44/igmm81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/44/igmm87.png" title="MLP4481"><br>
 &emsp; b) 33 point split<br>
  &emsp;  &emsp;  i) &emsp;Direct Approach Results<br>
  &emsp;  &emsp; &emsp;  1) &emsp;MLP<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 632.74<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy 82.54%<br>
  <img src="./docs/assets/css/33/dmlp81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/33/dmlp87.png" title="MLP4481"><br>
  &emsp;  &emsp; &emsp;  2) &emsp;RFR<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 1024.48<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 80.14%<br>
  <img src="./docs/assets/css/33/drf81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/33/drf87.png" title="MLP4481"><br>
  &emsp;  &emsp; &emsp;  3) &emsp;Lasso<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 4314.65<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 65.79%<br>
  <img src="./docs/assets/css/33/dl81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/33/dl87.png" title="MLP4481"><br>
  &emsp;  &emsp; ii) &emsp;Iterative Architecture and Iterative with Soft-clustering Results<br>
  &emsp;  &emsp; &emsp;  1) &emsp;MLP<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 1959.22<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 61.96%<br>
  <img src="./docs/assets/css/44/imlp81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/44/imlp87.png" title="MLP4481"><br>
  &emsp;  &emsp; &emsp;  2) &emsp;RFR<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 1001.03<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 78.23%<br>
  <img src="./docs/assets/css/33/irf81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/33/irf87.png" title="MLP4481"><br>
  &emsp;  &emsp; &emsp;  3) &emsp;GMM<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 1530.63<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 76.08%<br>
  <img src="./docs/assets/css/33/igmm81.png" title="MLP4481"><br>
  <img src="./docs/assets/css/33/igmm87.png" title="MLP4481"><br>
  &emsp; c) 22 point split (not done)<br>
  &emsp;  &emsp;  i) &emsp;Direct Approach Results<br>
  &emsp;  &emsp; &emsp;  1) &emsp;MLP<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 755.99<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 755.99<br>
  &emsp;  &emsp; &emsp;  2) &emsp;RFR<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 755.99<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 755.99<br>
  &emsp;  &emsp; &emsp;  3) &emsp;Lasso<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 755.99<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 755.99<br>
  &emsp;  &emsp; ii) &emsp;Iterative Architecture and Iterative with Soft-clustering Results<br>
  &emsp;  &emsp; &emsp;  1) &emsp;MLP<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 755.99<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 755.99<br>
  &emsp;  &emsp; &emsp;  2) &emsp;RFR<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 755.99<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 755.99<br>
  &emsp;  &emsp; &emsp;  3) &emsp;GMM<br>
  &emsp;&emsp;&emsp;  &emsp; The MSE is 755.99<br>
  &emsp;&emsp;&emsp;  &emsp; The accuracy is 755.99<br>
  &emsp;  d) Comparison and Conclusions<br>
  &emsp;&emsp;&emsp;  &emsp; The neural network predicted a similar result to the Random Tree Regression.<br>
  
  &emsp; e) Next Steps<br>
  &emsp;&emsp; &emsp;These results suggest that we should attempt a different approach. Rather <br>
</p>
<h2>5) References</h2>
<p>
[1] J. Lu, <q>Machine learning modeling for time series problem: Predicting <br>
  &emsp; flight ticket prices,</q> arXiv.org, https://arxiv.org/abs/1705.07205 <br>
  &emsp; (accessed Jun. 11, 2024). <br>
[2] S. Gupta and N. Gupta, Flight fare prediction using machine learning, <br>
  &emsp; https://www.researchgate.net/publication/380296130_Flight_Fare_Pr<br>
  &emsp; ediction_Using_Machine_Learning (accessed Jun. 11, 2024).<br>
[3] K. Tziridis, Th. Kalampokas, G. A. Papakostas, and K. I. Diamantaras, <br>
  &emsp; Airfare prices prediction using Machine Learning Techniques, <br>
  &emsp; https://ieeexplore.ieee.org/document/8081365/ (accessed Jun. 11, 2024).
</p>
<h2>Gantt Chart</h2>
<a href="https://docs.google.com/spreadsheets/d/1p2POTEbhSWqfBzq0sjRmW3fbHE6IvLSu8YKhsBswh4A/edit?gid=1989857755#gid=1989857755">Gantt Chart</a>
<h2>Contribution Table</h2>
<table>
  <tr>
    <th>Name</th>
    <th>Proposal Contributions</th>
    <th>Midterm Contributions</th>
    <th>Final Contributions</th>
  </tr>
  <tr>
    <td> Francesco Cascone </td>
    <td> Gathering References, Writing the Report</td>
    <td> Preprocessing and Visualizing Data </td>
    <td> Direct Archtiecture, Visualizations </td>
  </tr>
  <tr>
    <td> William Hudson </td>
    <td> Video Presentation</td>
    <td> Github Pages, Prediction Analysis </td>
    <td> Final Report, Direct Archtiecture, Github Pages </td>
  </tr>
  <tr>
    <td> Viabhav Patel </td>
    <td> Gathering References, Writing the Report</td>
    <td> Preprocessing Data, Running Random Forests, Running DNN </td>
    <td> Video Presentation </td>
  </tr>
  <tr>
    <td> Matthew Spenney </td>
    <td> Github Repository, Github Pages</td>
    <td> Github Pages, Prediction Analysis </td>
    <td> Iterative Architectures, Github Pages </td>
  </tr>
  <tr>
    <td> Jonathan Zhang </td>
    <td> Writing the Report</td>
    <td> Running Random Forests </td>
    <td> Final Report, and Video Slides </td>
  </tr>
</table>
</body>
</html>
